# -*- coding: utf-8 -*-
"""
æ•°æ®å¤„ç†æ¨¡å—
è´Ÿè´£CSVæ–‡ä»¶çš„æ›´æ–°ã€ç´¯è®¡å€¼è®¡ç®—å’Œå¤‡ä»½
"""
import csv
import os
import shutil
from datetime import datetime
from typing import List, Dict, Optional
from ..core.logger import get_logger


class DataProcessor:
    """æ•°æ®å¤„ç†å™¨ç±»"""

    def __init__(self, data_dir: str = "data", backup_dir: str = "data/backup",
                 daily_raw_dir: str = "data/daily_raw"):
        """
        åˆå§‹åŒ–æ•°æ®å¤„ç†å™¨

        Args:
            data_dir: ä¸»æ•°æ®ç›®å½•
            backup_dir: å¤‡ä»½ç›®å½•
            daily_raw_dir: æ¯æ—¥åŸå§‹æ•°æ®ç›®å½•
        """
        self.data_dir = data_dir
        self.backup_dir = backup_dir
        self.daily_raw_dir = daily_raw_dir
        self.log = get_logger()

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self._ensure_directories()

    def _ensure_directories(self):
        """ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„ç›®å½•éƒ½å­˜åœ¨"""
        for directory in [self.data_dir, self.backup_dir, self.daily_raw_dir]:
            if not os.path.exists(directory):
                os.makedirs(directory)
                self.log(f"åˆ›å»ºç›®å½•: {directory}")

    def save_daily_raw_data(self, data: List[List[str]], filename: str) -> Optional[str]:
        """
        ä¿å­˜æ¯æ—¥åŸå§‹æ•°æ®

        Args:
            data: CSVæ•°æ®ï¼ˆåŒ…å«è¡¨å¤´ï¼‰
            filename: æ–‡ä»¶å

        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        if not data:
            self.log("æ²¡æœ‰æ•°æ®å¯ä¿å­˜", "WARNING")
            return None

        filepath = os.path.join(self.daily_raw_dir, filename)

        try:
            with open(filepath, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerows(data)

            self.log(f"åŸå§‹æ•°æ®å·²ä¿å­˜: {filepath}", "SUCCESS")
            return filepath

        except Exception as e:
            self.log(f"ä¿å­˜åŸå§‹æ•°æ®å¤±è´¥: {e}", "ERROR")
            return None

    def load_csv_data(self, filepath: str) -> Optional[List[List[str]]]:
        """
        åŠ è½½CSVæ•°æ®

        Args:
            filepath: CSVæ–‡ä»¶è·¯å¾„

        Returns:
            List[List[str]]: CSVæ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        if not os.path.exists(filepath):
            return None

        try:
            with open(filepath, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                data = list(reader)
            return data
        except Exception as e:
            self.log(f"åŠ è½½CSVå¤±è´¥: {e}", "ERROR")
            return None

    def append_to_master_file(self, data: List[str], master_filename: str) -> bool:
        """
        å°†æ•°æ®è¿½åŠ åˆ°ä¸»æ–‡ä»¶

        Args:
            data: å•è¡Œæ•°æ®ï¼ˆä¸åŒ…å«è¡¨å¤´ï¼‰
            master_filename: ä¸»æ–‡ä»¶å

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        master_path = os.path.join(self.data_dir, master_filename)

        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»ºå¹¶å†™å…¥è¡¨å¤´
            file_exists = os.path.exists(master_path)

            with open(master_path, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)

                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå†™å…¥è¡¨å¤´ï¼ˆå‡è®¾dataç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´ï¼‰
                if not file_exists and len(data) > 0:
                    # è¿™é‡Œå‡è®¾è°ƒç”¨è€…ä¼šå¤„ç†è¡¨å¤´
                    pass

                writer.writerow(data)

            self.log(f"æ•°æ®å·²è¿½åŠ åˆ°ä¸»æ–‡ä»¶: {master_path}")
            return True

        except Exception as e:
            self.log(f"è¿½åŠ æ•°æ®å¤±è´¥: {e}", "ERROR")
            return False

    def calculate_cumulative_values(self, master_filename: str,
                                    air_time_col: int = 0, block_time_col: int = 1) -> Dict[str, float]:
        """
        è®¡ç®—ç´¯è®¡å€¼ï¼ˆä¾‹å¦‚ç´¯è®¡é£è¡Œæ—¶é—´ï¼‰

        Args:
            master_filename: ä¸»æ–‡ä»¶å
            air_time_col: é£è¡Œæ—¶é—´åˆ—ç´¢å¼•
            block_time_col: è½®æŒ¡æ—¶é—´åˆ—ç´¢å¼•

        Returns:
            Dict[str, float]: {'total_air_time': x, 'total_block_time': y}
        """
        master_path = os.path.join(self.data_dir, master_filename)

        if not os.path.exists(master_path):
            return {'total_air_time': 0.0, 'total_block_time': 0.0}

        try:
            total_air_time = 0.0
            total_block_time = 0.0

            with open(master_path, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                next(reader, None)  # è·³è¿‡è¡¨å¤´

                for row in reader:
                    if len(row) > max(air_time_col, block_time_col):
                        try:
                            if row[air_time_col]:
                                total_air_time += float(row[air_time_col])
                            if row[block_time_col]:
                                total_block_time += float(row[block_time_col])
                        except ValueError:
                            continue

            return {
                'total_air_time': round(total_air_time, 2),
                'total_block_time': round(total_block_time, 2)
            }

        except Exception as e:
            self.log(f"è®¡ç®—ç´¯è®¡å€¼å¤±è´¥: {e}", "ERROR")
            return {'total_air_time': 0.0, 'total_block_time': 0.0}

    def backup_file(self, filepath: str) -> Optional[str]:
        """
        å¤‡ä»½æ–‡ä»¶

        Args:
            filepath: è¦å¤‡ä»½çš„æ–‡ä»¶è·¯å¾„

        Returns:
            str: å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        if not os.path.exists(filepath):
            self.log(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•å¤‡ä»½: {filepath}", "WARNING")
            return None

        try:
            # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶åï¼ˆæ·»åŠ æ—¶é—´æˆ³ï¼‰
            filename = os.path.basename(filepath)
            name, ext = os.path.splitext(filename)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"{name}_{timestamp}{ext}"
            backup_path = os.path.join(self.backup_dir, backup_filename)

            # å¤åˆ¶æ–‡ä»¶
            shutil.copy2(filepath, backup_path)

            self.log(f"æ–‡ä»¶å·²å¤‡ä»½: {backup_path}", "SUCCESS")
            return backup_path

        except Exception as e:
            self.log(f"å¤‡ä»½å¤±è´¥: {e}", "ERROR")
            return None

    def cleanup_old_daily_raw(self, days: int = 30):
        """
        æ¸…ç†è¿‡æœŸçš„æ¯æ—¥åŸå§‹æ•°æ®æ–‡ä»¶

        Args:
            days: ä¿ç•™å¤©æ•°
        """
        if not os.path.exists(self.daily_raw_dir):
            return

        cutoff_time = datetime.now().timestamp() - (days * 24 * 60 * 60)

        for filename in os.listdir(self.daily_raw_dir):
            if not filename.endswith(".csv"):
                continue

            filepath = os.path.join(self.daily_raw_dir, filename)

            if os.path.getmtime(filepath) < cutoff_time:
                try:
                    os.remove(filepath)
                    self.log(f"å·²åˆ é™¤è¿‡æœŸåŸå§‹æ•°æ®: {filename}")
                except Exception as e:
                    self.log(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {filename}: {e}", "ERROR")

    def get_latest_file_info(self, pattern: str = "*.csv") -> Optional[Dict[str, str]]:
        """
        è·å–æœ€æ–°çš„æ–‡ä»¶ä¿¡æ¯

        Args:
            pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼

        Returns:
            Dict[str, str]: {'filename': xxx, 'path': xxx, 'mtime': xxx}
        """
        import glob

        files = glob.glob(os.path.join(self.daily_raw_dir, pattern))

        if not files:
            return None

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        latest_file = max(files, key=os.path.getmtime)

        return {
            'filename': os.path.basename(latest_file),
            'path': latest_file,
            'mtime': datetime.fromtimestamp(os.path.getmtime(latest_file)).strftime("%Y-%m-%d %H:%M:%S")
        }


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æ•°æ®å¤„ç†å™¨æµ‹è¯•")
    print("="*60)

    processor = DataProcessor()

    # æµ‹è¯•æ•°æ®
    test_data = [
        ['air_time', 'block_time', 'fc', 'flight_leg'],
        ['10.5', '12.3', 'C909', 'SHA-PEK'],
        ['8.2', '9.8', 'C909', 'PEK-SHA']
    ]

    # ä¿å­˜åŸå§‹æ•°æ®
    print("\nğŸ“ æµ‹è¯•ä¿å­˜åŸå§‹æ•°æ®...")
    filepath = processor.save_daily_raw_data(test_data, "test_data.csv")
    print(f"ä¿å­˜è·¯å¾„: {filepath}")

    # è¯»å–æ•°æ®
    if filepath:
        print("\nğŸ“– æµ‹è¯•è¯»å–æ•°æ®...")
        loaded_data = processor.load_csv_data(filepath)
        print(f"æ•°æ®è¡Œæ•°: {len(loaded_data) if loaded_data else 0}")

    # å¤‡ä»½æ–‡ä»¶
    if filepath:
        print("\nğŸ’¾ æµ‹è¯•å¤‡ä»½æ–‡ä»¶...")
        backup_path = processor.backup_file(filepath)
        print(f"å¤‡ä»½è·¯å¾„: {backup_path}")

    # è·å–æœ€æ–°æ–‡ä»¶
    print("\nğŸ” æµ‹è¯•è·å–æœ€æ–°æ–‡ä»¶...")
    latest = processor.get_latest_file_info()
    if latest:
        print(f"æœ€æ–°æ–‡ä»¶: {latest['filename']}")
        print(f"ä¿®æ”¹æ—¶é—´: {latest['mtime']}")

    print("\nâœ… æµ‹è¯•å®Œæˆ")

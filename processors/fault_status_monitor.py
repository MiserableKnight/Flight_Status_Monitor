# -*- coding: utf-8 -*-
"""
æ•…éšœçŠ¶æ€ç›‘æ§è„šæœ¬

åŠŸèƒ½ï¼š
- è¯»å–æ¯æ—¥æ•…éšœæ•°æ®
- ç”Ÿæˆæ•…éšœæ±‡æ€»ä¿¡æ¯
- å‘é€æ•…éšœé‚®ä»¶é€šçŸ¥ï¼ˆæ¯å¤©ä¸€æ¬¡ï¼‰
"""
import pandas as pd
from datetime import datetime
import os
import sys
import hashlib

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from core.logger import get_logger
from core.fault_status_notifier import FaultStatusNotifier
from config.config_loader import load_config

# åˆå§‹åŒ–æ—¥å¿—
log = get_logger()

# åŠ è½½ç»Ÿä¸€é…ç½®
config_loader = load_config()
gmail_config = config_loader.get_gmail_config()


def generate_fault_summary(df, target_date):
    """
    ç”Ÿæˆæ•…éšœæ±‡æ€»ä¿¡æ¯

    Args:
        df: æ•…éšœæ•°æ®DataFrame
        target_date: ç›®æ ‡æ—¥æœŸ

    Returns:
        str: æ•…éšœæ±‡æ€»æ–‡æœ¬
    """
    if df.empty:
        return f"æ•…éšœä¿¡æ¯æ±‡æ€» - {target_date}\n{'='*40}\n\nä»Šæ—¥æ— æ•…éšœè®°å½•\n"

    # æŒ‰é£æœºåˆ†ç»„
    aircraft_groups = df.groupby('æœºå·')

    summary_lines = [
        f"æ•…éšœä¿¡æ¯æ±‡æ€» - {target_date}",
        "="*40,
        ""
    ]

    total_faults = 0

    for aircraft_num, group in aircraft_groups:
        summary_lines.append(f"{aircraft_num}:")

        # æŒ‰èˆªç­å·åˆ†ç»„
        flight_groups = group.groupby('èˆªç­å·')

        for flight_num, flight_group in flight_groups:
            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰è§¦å‘æ—¶é—´æ’åº
            faults = flight_group.to_dict('records')
            faults.sort(key=lambda x: x['è§¦å‘æ—¶é—´'], reverse=True)

            flight_line = f"  {flight_num}:"
            fault_lines = []

            for fault in faults:
                total_faults += 1
                trigger_time = fault['è§¦å‘_time'] if 'è§¦å‘_time' in fault else fault.get('è§¦å‘æ—¶é—´', '')

                # æ ¼å¼åŒ–æ•…éšœæè¿°
                description = fault.get('æè¿°', '')
                fault_type = fault.get('æ•…éšœç±»å‹', '')
                phase = fault.get('é£è¡Œé˜¶æ®µ', '')

                # ç®€åŒ–æ˜¾ç¤ºï¼šåªæ˜¾ç¤ºæ—¶é—´å’Œæè¿°
                if phase:
                    fault_lines.append(f"    - {description} ({trigger_time}, {phase})")
                else:
                    fault_lines.append(f"    - {description} ({trigger_time})")

            if fault_lines:
                summary_lines.append(flight_line)
                summary_lines.extend(fault_lines[:10])  # æœ€å¤šæ˜¾ç¤º10æ¡
                if len(fault_lines) > 10:
                    summary_lines.append(f"    ... (è¿˜æœ‰{len(fault_lines)-10}æ¡)")

        summary_lines.append("")

    summary_lines.extend([
        "-"*40,
        f"å…±è®¡: {total_faults}æ¡æ•…éšœè®°å½•"
    ])

    return '\n'.join(summary_lines)


def monitor_fault_status(target_date=None):
    """
    ç›‘æ§æ•…éšœçŠ¶æ€å¹¶å‘é€é€šçŸ¥

    é€»è¾‘ï¼š
    1. è¯»å–å½“æ—¥æ•…éšœæ•°æ®
    2. ç”Ÿæˆæ•…éšœæ±‡æ€»
    3. å¯¹æ¯”ä¸Šæ¬¡é‚®ä»¶çŠ¶æ€å“ˆå¸Œ
    4. åªæœ‰æ•°æ®å˜åŒ–æ‰å‘é€é‚®ä»¶
    5. å‘é€æˆåŠŸåä¿å­˜å½“å‰çŠ¶æ€

    Args:
        target_date: ç›®æ ‡æ—¥æœŸï¼ˆYYYY-MM-DDæ ¼å¼ï¼‰ï¼Œé»˜è®¤ä¸ºä»Šå¤©
    """
    log("æ•…éšœçŠ¶æ€ç›‘æ§è„šæœ¬å¯åŠ¨")

    if target_date is None:
        target_date = datetime.now().strftime('%Y-%m-%d')

    print(f"ğŸ“… ç›‘æ§æ—¥æœŸï¼š{target_date}")

    # è¯»å– daily_raw ä¸­æœ€æ–°æŠ“å–çš„æ•°æ®
    daily_file = os.path.join(project_root, 'data', 'daily_raw', f'fault_data_{target_date}.csv')

    if not os.path.exists(daily_file):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {daily_file}")
        log(f"Data file not found: {daily_file}", "ERROR")
        return False

    try:
        # è¯»å–CSVæ–‡ä»¶ï¼Œå¤„ç†å¯èƒ½çš„ç¼–ç é—®é¢˜
        try:
            df = pd.read_csv(daily_file, encoding='utf-8-sig')
        except:
            df = pd.read_csv(daily_file, encoding='gbk')

        # é‡å‘½åå¯èƒ½çš„åˆ—åå˜ä½“ï¼ˆå¤„ç†ç¼–ç é—®é¢˜ï¼‰
        if 'è§¦å‘_time' in df.columns and 'è§¦å‘æ—¶é—´' not in df.columns:
            df.rename(columns={'è§¦å‘_time': 'è§¦å‘æ—¶é—´'}, inplace=True)

        print(f"   âœ… è¯»å–åˆ° {len(df)} è¡Œæ•°æ®")
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®æ–‡ä»¶å¤±è´¥ï¼š{e}")
        log(f"Failed to read data: {e}", "ERROR")
        return False

    # ç”Ÿæˆæ•…éšœæ±‡æ€»
    print("\nğŸ“Š ç”Ÿæˆæ•…éšœæ±‡æ€»...")
    fault_summary = generate_fault_summary(df, target_date)

    # ç”Ÿæˆå½“å‰æ•°æ®çš„å”¯ä¸€æ ‡è¯†ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    current_hash = hashlib.md5(
        f"{target_date}_{len(df)}".encode('utf-8')
    ).hexdigest()

    # åŠ è½½ä¸Šæ¬¡å‘é€çš„é‚®ä»¶çŠ¶æ€
    last_email_status_file = os.path.join(project_root, 'data', 'last_fault_email_status.json')
    last_hash = None

    if os.path.exists(last_email_status_file):
        try:
            import json
            with open(last_email_status_file, 'r', encoding='utf-8') as f:
                last_email_data = json.load(f)
                last_hash = last_email_data.get('data_hash')
                print(f"   ğŸ“‹ ä¸Šæ¬¡é‚®ä»¶æ•°æ®å“ˆå¸Œ: {last_hash}")
        except Exception as e:
            print(f"   âš ï¸ è¯»å–ä¸Šæ¬¡é‚®ä»¶çŠ¶æ€å¤±è´¥: {e}")

    # å¯¹æ¯”çŠ¶æ€
    print(f"   ğŸ“Š å½“å‰æ•°æ®å“ˆå¸Œ: {current_hash}")

    if current_hash == last_hash:
        print(f"\n   â„¹ï¸ æ•°æ®æ— å˜åŒ–ï¼Œè·³è¿‡é‚®ä»¶å‘é€")
        log("No data changes detected, skipping email notification", "INFO")
        return True

    print(f"\n   âœ… æ£€æµ‹åˆ°æ•°æ®å˜åŒ–ï¼Œå‘é€é‚®ä»¶é€šçŸ¥")

    # å‘é€é€šçŸ¥ï¼ˆä½¿ç”¨ç»Ÿä¸€é…ç½®ï¼‰
    notifier = FaultStatusNotifier(config_dict=gmail_config)

    if notifier.is_enabled():
        # å‡†å¤‡é™„ä»¶è·¯å¾„
        attachment = daily_file if os.path.exists(daily_file) else None

        if notifier.send_fault_status_notification(fault_summary, target_date, attachment):
            print(f"   âœ… å·²å‘é€æ•…éšœæ±‡æ€»é‚®ä»¶")
            log(f"Sent fault status notification for {target_date}", "SUCCESS")

            # ä¿å­˜å½“å‰é‚®ä»¶çŠ¶æ€
            try:
                import json
                os.makedirs(os.path.dirname(last_email_status_file), exist_ok=True)
                with open(last_email_status_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'data_hash': current_hash,
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'fault_count': len(df),
                        'date': target_date
                    }, f, ensure_ascii=False, indent=2)
                print(f"   ğŸ’¾ å·²ä¿å­˜å½“å‰é‚®ä»¶çŠ¶æ€")
            except Exception as e:
                print(f"   âš ï¸ ä¿å­˜é‚®ä»¶çŠ¶æ€å¤±è´¥: {e}")
        else:
            print(f"   âš ï¸ é‚®ä»¶å‘é€å¤±è´¥")
            return False
    else:
        print(f"   âš ï¸ é‚®ä»¶é€šçŸ¥æœªå¯ç”¨")
        # æ‰“å°é€šçŸ¥å†…å®¹
        print("\nğŸ“§ é€šçŸ¥å†…å®¹ï¼š")
        print(fault_summary)

    return True


if __name__ == "__main__":
    print("=" * 60)
    print("æ•…éšœçŠ¶æ€ç›‘æ§è„šæœ¬")
    print("=" * 60)

    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šæ—¥æœŸ
    target_date = None
    if len(sys.argv) > 1:
        target_date = sys.argv[1]

    success = monitor_fault_status(target_date)

    if success:
        print("\nâœ… ç›‘æ§å®Œæˆï¼")
        sys.exit(0)
    else:
        print("\nâš ï¸ ç›‘æ§å¤±è´¥")
        sys.exit(1)
